{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2c57d12f",
   "metadata": {},
   "source": [
    "# This notebook imports the semantic network built and visualizes it given a starting node in a interactive way"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "873f5ea4",
   "metadata": {},
   "source": [
    "## 0. Imports and setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "16298db0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 2: imports & config\n",
    "import networkx as nx\n",
    "import pandas as pd\n",
    "from pyvis.network import Network\n",
    "from IPython.display import IFrame, display\n",
    "import numpy as np\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# Files you exported previously\n",
    "GEXF_PATH = \"materials_semantic_network.gexf\"     # or use GraphML if you prefer\n",
    "# CSVs are not required for the viz, but handy to debug:\n",
    "NODES_CSV = \"materials_semantic_nodes.csv\"\n",
    "EDGES_CSV = \"materials_semantic_edges.csv\"\n",
    "\n",
    "# Category colors\n",
    "COLOR_BY_CATEGORY = {\n",
    "    \"source\":      \"#1f77b4\",  # blue\n",
    "    \"function\":    \"#2ca02c\",  # green\n",
    "    \"application\": \"#d62728\",  # red\n",
    "}\n",
    "\n",
    "# Tolerance for floating-point comparisons\n",
    "W1_TOL = 0.1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b8eb566",
   "metadata": {},
   "source": [
    "## 1. Load graph and normalize attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "42a1273b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded graph: 6800 nodes, 36695 edges\n"
     ]
    }
   ],
   "source": [
    "# Cell 3: load graph and normalize attributes\n",
    "G = nx.read_gexf(GEXF_PATH)  # preserves node/edge attributes\n",
    "\n",
    "def normalize_graph(G):\n",
    "    # Standardize node attributes: ensure 'label' and 'category'\n",
    "    for n, d in G.nodes(data=True):\n",
    "        if \"label\" not in d or not str(d[\"label\"]).strip():\n",
    "            # fall back: strip the prefix if you used \"type::label\" as node id\n",
    "            label_guess = str(n).split(\"::\", 1)[-1]\n",
    "            d[\"label\"] = label_guess\n",
    "        # some builds used 'type' instead of 'category'\n",
    "        if \"category\" not in d or not str(d[\"category\"]).strip():\n",
    "            if \"type\" in d and str(d[\"type\"]).strip():\n",
    "                d[\"category\"] = str(d[\"type\"]).strip()\n",
    "            else:\n",
    "                # last fallback: try to infer from node id prefix\n",
    "                if \"::\" in str(n):\n",
    "                    d[\"category\"] = str(n).split(\"::\", 1)[0]\n",
    "                else:\n",
    "                    d[\"category\"] = \"unknown\"\n",
    "        # lower-case category for consistency\n",
    "        d[\"category\"] = str(d[\"category\"]).lower().strip()\n",
    "\n",
    "    # Standardize edge attributes: ensure 'edge_type' and 'weight'\n",
    "    for u, v, d in G.edges(data=True):\n",
    "        # some builds used 'kind' (e.g., 'cooc' or 'sim')\n",
    "        et = d.get(\"edge_type\") or d.get(\"kind\") or \"\"\n",
    "        et = str(et).lower().strip()\n",
    "        # map short labels\n",
    "        if et == \"cooc\":\n",
    "            et = \"cooccurrence\"\n",
    "        elif et == \"sim\":\n",
    "            et = \"similarity\"\n",
    "        d[\"edge_type\"] = et if et else \"unknown\"\n",
    "\n",
    "        if \"weight\" not in d:\n",
    "            d[\"weight\"] = 1.0\n",
    "        else:\n",
    "            try:\n",
    "                d[\"weight\"] = float(d[\"weight\"])\n",
    "            except Exception:\n",
    "                d[\"weight\"] = 1.0\n",
    "\n",
    "normalize_graph(G)\n",
    "print(f\"Loaded graph: {G.number_of_nodes()} nodes, {G.number_of_edges()} edges\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3718f3ac",
   "metadata": {},
   "source": [
    "## 2. sBERT setup for node search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d61e1844",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'source': 1314, 'function': 4144, 'application': 1342}\n"
     ]
    }
   ],
   "source": [
    "# Pick the same model you used for intra-category edges for consistency\n",
    "SBERT_MODEL = \"all-MiniLM-L6-v2\"  # or your previous choice\n",
    "sbert = SentenceTransformer(SBERT_MODEL)\n",
    "\n",
    "def _normalize(v):\n",
    "    v = np.asarray(v, dtype=np.float32)\n",
    "    n = np.linalg.norm(v, axis=-1, keepdims=True) + 1e-12\n",
    "    return v / n\n",
    "\n",
    "# Caches: node_ids, labels, and normalized embeddings by category\n",
    "cat_cache = {\n",
    "    \"source\":    {\"nodes\": [], \"labels\": [], \"emb\": None},\n",
    "    \"function\":  {\"nodes\": [], \"labels\": [], \"emb\": None},\n",
    "    \"application\":{\"nodes\": [], \"labels\": [], \"emb\": None},\n",
    "}\n",
    "\n",
    "def rebuild_category_embeddings(G):\n",
    "    for cat in cat_cache.keys():\n",
    "        nodes, labels = [], []\n",
    "        for n, d in G.nodes(data=True):\n",
    "            if d.get(\"category\") == cat:\n",
    "                nodes.append(n)\n",
    "                labels.append(d.get(\"label\", n))\n",
    "        if labels:\n",
    "            embs = sbert.encode(labels, batch_size=256, show_progress_bar=False)\n",
    "            embs = _normalize(embs)\n",
    "        else:\n",
    "            embs = np.zeros((0, 384), dtype=np.float32)  # dimension depends on model\n",
    "        cat_cache[cat][\"nodes\"]  = nodes\n",
    "        cat_cache[cat][\"labels\"] = labels\n",
    "        cat_cache[cat][\"emb\"]    = embs\n",
    "\n",
    "rebuild_category_embeddings(G)\n",
    "print({k: len(v[\"nodes\"]) for k,v in cat_cache.items()})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c168ffd",
   "metadata": {},
   "source": [
    "## 3. Helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ff779de1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 4: helpers for querying and filtering\n",
    "\n",
    "def norm_text(s: str) -> str:\n",
    "    return \" \".join(str(s).strip().lower().split())\n",
    "\n",
    "#def search_nodes(G, query, category=None, max_results=50):\n",
    "#    \"\"\"\n",
    "#    Case-insensitive substring search on node 'label'.\n",
    "#    Optionally filter by 'category' in {'source','function','application'}.\n",
    "#    \"\"\"\n",
    "#    q = norm_text(query)\n",
    "#    out = []\n",
    "#    for n, d in G.nodes(data=True):\n",
    "#        if category and d.get(\"category\") != category:\n",
    "#            continue\n",
    "#        if q in norm_text(d.get(\"label\", \"\")):\n",
    "#            out.append(n)\n",
    "#            if len(out) >= max_results:\n",
    "#                break\n",
    "#    return out\n",
    "\n",
    "def search_nodes_semantic(G, query, category, top_k=1):\n",
    "    \"\"\"\n",
    "    Find the most semantically similar node(s) to `query` within a given category\n",
    "    using sBERT cosine similarity. Returns list of (node_id, label, score).\n",
    "    \"\"\"\n",
    "    category = category.lower()\n",
    "    if category not in cat_cache:\n",
    "        raise ValueError(\"category must be one of {'source','function','application'}\")\n",
    "\n",
    "    labels = cat_cache[category][\"labels\"]\n",
    "    embs   = cat_cache[category][\"emb\"]\n",
    "    nodes  = cat_cache[category][\"nodes\"]\n",
    "\n",
    "    if embs is None or len(nodes) == 0:\n",
    "        return []\n",
    "\n",
    "    q_emb = sbert.encode([query], show_progress_bar=False)\n",
    "    q_emb = _normalize(q_emb)[0]  # shape (d,)\n",
    "\n",
    "    # cosine similarity = dot product on normalized vectors\n",
    "    sims = embs @ q_emb\n",
    "    idx  = np.argpartition(-sims, min(top_k, len(sims)-1))[:top_k]\n",
    "    idx  = idx[np.argsort(-sims[idx])]\n",
    "\n",
    "    return [nodes[i] for i in idx]\n",
    "\n",
    "def build_cooccurrence_only_graph(G):\n",
    "    \"\"\"\n",
    "    Keep only edges where edge_type == 'cooccurrence' AND weight â‰ˆ 1.\n",
    "    Remove all other edges.\n",
    "    \"\"\"\n",
    "    H = nx.Graph()\n",
    "    for n, d in G.nodes(data=True):\n",
    "        H.add_node(n, **d)\n",
    "    for u, v, d in G.edges(data=True):\n",
    "        if d.get(\"edge_type\") == \"cooccurrence\" and abs(d.get(\"weight\", 1.0) - 1.0) <= W1_TOL:\n",
    "            H.add_edge(u, v, **d)\n",
    "    return H\n",
    "\n",
    "def ego_subgraph_from_seeds(H, seeds, radius=2):\n",
    "    \"\"\"\n",
    "    Union of ego graphs (radius hops) around each seed in H.\n",
    "    \"\"\"\n",
    "    seeds = [s for s in seeds if s in H]\n",
    "    if not seeds:\n",
    "        return nx.Graph()  # empty\n",
    "    S = nx.Graph()\n",
    "    for s in seeds:\n",
    "        E = nx.ego_graph(H, s, radius=radius)\n",
    "        S = nx.compose(S, E)\n",
    "    return S\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e8c10d6",
   "metadata": {},
   "source": [
    "## 3. Pick query and build"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "13debdbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matches found (1): ['high precision 3d printed objects']\n",
      "Co-occurrence-only graph: 6800 nodes, 10753 edges\n",
      "Subgraph for viz: 22 nodes, 26 edges\n"
     ]
    }
   ],
   "source": [
    "# Cell 5: set your query and (optionally) restrict to a category\n",
    "QUERY_TEXT   = \"3D-printing\"       # <-- change this to your search term\n",
    "QUERY_CAT    = \"application\"          # None, or \"source\"/\"function\"/\"application\"\n",
    "EGO_RADIUS   = 2            # hops around the seed(s)\n",
    "\n",
    "# 1) Find matching nodes\n",
    "matches = search_nodes_semantic(G, QUERY_TEXT, category=QUERY_CAT, top_k=1)\n",
    "print(f\"Matches found ({len(matches)}): {[G.nodes[n]['label'] for n in matches[:10]]}\")\n",
    "\n",
    "# 2) Build co-occurrence-only graph\n",
    "G_cooc = build_cooccurrence_only_graph(G)\n",
    "print(f\"Co-occurrence-only graph: {G_cooc.number_of_nodes()} nodes, {G_cooc.number_of_edges()} edges\")\n",
    "\n",
    "# 3) Extract an ego subgraph from matches (using only co-occurrence edges)\n",
    "S = ego_subgraph_from_seeds(G_cooc, matches, radius=EGO_RADIUS)\n",
    "print(f\"Subgraph for viz: {S.number_of_nodes()} nodes, {S.number_of_edges()} edges\")\n",
    "\n",
    "# Optional pruning if the subgraph is too large\n",
    "MAX_NODES = 300\n",
    "if S.number_of_nodes() > MAX_NODES:\n",
    "    # keep seeds + their neighbors up to degree sort\n",
    "    keep = set(matches)\n",
    "    # add neighbors until cap\n",
    "    for m in matches:\n",
    "        keep.update(list(S.neighbors(m)))\n",
    "        if len(keep) >= MAX_NODES:\n",
    "            break\n",
    "    S = S.subgraph(list(keep)).copy()\n",
    "    print(f\"Pruned to {S.number_of_nodes()} nodes, {S.number_of_edges()} edges\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6dc1e92",
   "metadata": {},
   "source": [
    "## 4. Interactive visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "a3779166",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "materials_cooccurrence_query.html\n",
      "Graph written: materials_cooccurrence_query.html\n",
      "Legend injected into: materials_cooccurrence_query.html\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"820\"\n",
       "            src=\"materials_cooccurrence_query.html\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x11d17cc20>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cell 6: Interactive visualization (Pyvis)\n",
    "HTML_OUT = \"materials_cooccurrence_query.html\"\n",
    "\n",
    "net = Network(height=\"800px\", width=\"100%\", bgcolor=\"#ffffff\", notebook=True, directed=False, cdn_resources='in_line')\n",
    "net.toggle_physics(False)\n",
    "# You can fine-tune physics via options if needed:\n",
    "# net.set_options('{\"physics\":{\"solver\":\"forceAtlas2Based\",\"forceAtlas2Based\":{\"gravitationalConstant\":-50}}}')\n",
    "\n",
    "# Add nodes with category colors and degree-based size\n",
    "for n, d in S.nodes(data=True):\n",
    "    label = d.get(\"label\", str(n))\n",
    "    cat   = d.get(\"category\", \"unknown\")\n",
    "    color = COLOR_BY_CATEGORY.get(cat, \"#888888\")\n",
    "    size  = 10 + 2 * S.degree(n)\n",
    "\n",
    "    # Tooltip title shows category\n",
    "    title = f\"{cat.capitalize()}: {label}\"\n",
    "    net.add_node(n, label=label, color=color, title=title, size=size)\n",
    "\n",
    "# Add edges (all are co-occurrence weight=1)\n",
    "for u, v, d in S.edges(data=True):\n",
    "    et = d.get(\"edge_type\", \"cooccurrence\")\n",
    "    net.add_edge(u, v, value=1, color=\"#555555\", title=et)\n",
    "\n",
    "net.show(HTML_OUT)\n",
    "print(\"Graph written:\", HTML_OUT)\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "overlay_html = \"\"\"\n",
    "<div id=\"legend-box\" style=\"\n",
    "  position:fixed; right:20px; bottom:20px;\n",
    "  background:#fff; border:1px solid #ccc; border-radius:6px;\n",
    "  padding:10px 12px; font: 13px/1.2 sans-serif; z-index: 999999;\n",
    "  box-shadow: 0 2px 8px rgba(0,0,0,0.15);\">\n",
    "  <div style=\"font-weight:600; margin-bottom:6px;\">Legend</div>\n",
    "  <div><span style=\"color:#4e79a7;\">&#9679;</span> Source</div>\n",
    "  <div><span style=\"color:#59a14f;\">&#9679;</span> Function</div>\n",
    "  <div><span style=\"color:#e15759;\">&#9679;</span> Application</div>\n",
    "</div>\n",
    "\"\"\"\n",
    "\n",
    "html_path = Path(HTML_OUT)\n",
    "html = html_path.read_text(encoding=\"utf-8\")\n",
    "\n",
    "# Insert the overlay just before </body>\n",
    "html = html.replace(\"</body>\", overlay_html + \"\\n</body>\")\n",
    "\n",
    "html_path.write_text(html, encoding=\"utf-8\")\n",
    "print(\"Legend injected into:\", HTML_OUT)\n",
    "\n",
    "IFrame(src=HTML_OUT, width=\"100%\", height=\"820\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
